# 2. Preperation
In the 2nd step we want to prepare our Google Colab Notebook. To do this, we upload the data set and install the necessary dependencies.  

## ✍Excercises
### 1. Upload the dataset
The first task is to upload the data set as a .zip archive and then to unpack it. The files should then be prepared in such a way that the tree structure shown below is achieved.    
  
⚠ Google Colab saves all uploaded files under /content/

### 2. Install the needed dependencies
Now you can install and import the necessary packages. We need python-opencv, tensorflow (tf), numpy (np), matplotlib (plt), os and keras. Note that some dependencies need to be installed with pip, while others are native Python packages. Use the "import ... as ..." syntax to abbreviate the imports to the names in the brackets if there is one. 

## 📃The file structure
-- dataset  
> |-- train  
>> | -- NORMAL  
>> | -- PNEUNOMIA  
> |-- test  
>> | -- NORMAL  
>> | -- PNEUNOMIA  


#### ℹDisclaimer
Of course, basic Python experience is not expected. If you have problems with this or the following tasks, you can simply use the cheat sheet, take a look at the solutions, contact me or use the internet.  
It's not about the programming language, but about being able to understand the basic procedure for computer vision problems.
